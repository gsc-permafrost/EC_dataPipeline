{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresh take\n",
    "\n",
    "## 1. Initalize sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dpth = r'G:\\My Drive\\FileDump\\SCL_Testing\\raw'\n",
    "dpth = r'U:\\EC_Backup\\SCL_Data\\20240912'\n",
    "dpth = r'E:\\GSC_Work\\SCL_Data\\20240912'\n",
    "\n",
    "\n",
    "fl = [f for f in os.listdir(dpth) if f.startswith()]\n",
    "fl.sort()\n",
    "print(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = r\"C:\\Users\\User\\GSC_Work\\SCL_2024\\Flux\\eddypro_t_full_output_2025-05-02T224906_exp.csv\"\n",
    "df = pd.read_csv(f,skiprows=[0,2],na_values=-9999)\n",
    "df.index = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "df['ch4_flux']*=1e3\n",
    "df.loc[((df['ch4_mean']<1.5)|(df['ch4_mean']>10)),['ch4_flux','ch4_mean']]=np.nan\n",
    "df.loc[((df['ch4_mean']<df['ch4_mean'].quantile(.01))|(df['ch4_mean']>df['ch4_mean'].quantile(.99))),['ch4_flux','ch4_mean']]=np.nan\n",
    "\n",
    "df.loc[((df['co2_mole_fraction']<375)|(df['co2_mole_fraction']>600)),['co2_flux','co2_mole_fraction']]=np.nan\n",
    "df.loc[((df['co2_mole_fraction']<df['co2_mole_fraction'].quantile(.01))|(df['co2_mole_fraction']>df['co2_mole_fraction'].quantile(.99))),['co2_flux','co2_mole_fraction']]=np.nan\n",
    "\n",
    "\n",
    "df.loc[df['qc_ch4_flux']>0,'ch4_flux']=np.nan\n",
    "df.loc[df['qc_co2_flux']>0,'co2_flux']=np.nan\n",
    "df.loc[df['u*']<=0.15,['ch4_flux','co2_flux']]=np.nan\n",
    "df.loc[df['co2_flux']>=20,['ch4_flux','co2_flux']]=np.nan\n",
    "df.loc[df['co2_flux']<=-20,['ch4_flux','co2_flux']]=np.nan\n",
    "for f in ['co2_flux','ch4_flux']:\n",
    "    df.loc[((df[f]>df[f].quantile(.99))|(df[f]<df[f].quantile(.01))),f]=np.nan\n",
    "\n",
    "fig,ax=plt.subplots(2)\n",
    "ax[0].plot(df['co2_flux'])\n",
    "ax[1].plot(df['co2_mole_fraction'])\n",
    "\n",
    "# df['u*']\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "df[['co2_flux','co2_mole_fraction','ch4_flux','ch4_mean']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from parseFiles import parseCSI,baseMethods\n",
    "import importlib\n",
    "importlib.reload(parseCSI)\n",
    "importlib.reload(baseMethods)\n",
    "import os\n",
    "TOB3 = r'parseFiles\\example_data\\Flux_Data640.dat'\n",
    "outputPath = r'E:\\GSC_Work\\SCL_Testing\\intermediate'\n",
    "# f = parseCSI.parseTOB3(sourceFile=TOB3,dropCols=['Diagnostic_CSAT'])\n",
    "# tmp = baseMethods.binBundle(variableMap=f.variableMap,DataFrame=f.DataFrame,filename=f.fileTimestamp,outputPath=outputPath)\n",
    "t = []\n",
    "r = []\n",
    "import time\n",
    "for f in fl:\n",
    "    if f.endswith('.dat'):\n",
    "        t1 = time.time()\n",
    "        TOB3 = os.path.join(dpth,f)\n",
    "        f = parseCSI.parseTOB3(sourceFile=TOB3,dropCols=['Diagnostic_CSAT'])\n",
    "        tmp = baseMethods.binBundle(variableMap=f.variableMap,DataFrame=f.DataFrame,filename=f.fileTimestamp,outputPath=outputPath,verbose=False)\n",
    "        t.append(f.DataFrame.index[0])\n",
    "        print((f.fileTimestamp))\n",
    "        diag_codes = (tmp.DataFrame[['Diagnostic_7700','RSSI']].groupby('Diagnostic_7700').agg(['count','mean']))\n",
    "        r.append(tmp.DataFrame['RSSI'].median())\n",
    "        print(time.time()-t1)\n",
    "plt.figure()\n",
    "plt.scatter(t,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "f = 'G:/My Drive/FileDump/SCL_Testing/intermediate/2024_09_08_0900.ecf32'\n",
    "# f = r\"\\\\wsl.localhost\\Ubuntu\\home\\jskeeter\\FluxCalc_engine\\custom\\binData\\2024_07_28_1930.float32_array\"\n",
    "# print(f)\n",
    "# float32_array = np.fromfile(f,dtype='float32')\n",
    "# print(float32_array.shape)\n",
    "# fn = f'{tmp.filename}.ecf32'\n",
    "# f = os.path.join(tmp.outputPath,fn)\n",
    "print(f)\n",
    "ecf32 = np.fromfile(f,dtype='float32')\n",
    "ecf32 = ecf32.reshape(-1,36000)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(0,4):\n",
    "    plt.plot(ecf32[i])\n",
    "# pd.to_datetime(np.fromfile('2024_07_28_1430.POSIX_timestamp'),unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fn = f'{tmp.filename}.tsf64'\n",
    "f = os.path.join(tmp.outputPath,fn)\n",
    "print(f)\n",
    "tsf64 = np.fromfile(f,dtype='float64')\n",
    "print(ecf32.reshape(tsf64.shape[0],-1).shape)\n",
    "print(float32_array.reshape(tsf64.shape[0],-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parseFiles import parseCSV\n",
    "import pandas as pd\n",
    "sf = r'example_data\\20240914\\20750528-SHSC.SSM.SGT.240720_240913readout.csv'\n",
    "import importlib\n",
    "importlib.reload(parseCSV)\n",
    "f = parseCSV.hoboCSV(sourceFile=sf,skiprows=1)\n",
    "print(f.variableMap)\n",
    "f.DataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from parseFiles import baseMethods\n",
    "importlib.reload(baseMethods)\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class parseDEF(baseMethods.genericLoggerFile):\n",
    "    defFile: str\n",
    "    defTimestamp: str = None\n",
    "    programName: str = None\n",
    "    LoggerModel: str = None\n",
    "    DEF: list = field(default_factory=lambda:[])\n",
    "    Arrays: dict = field(default_factory=lambda:{})\n",
    "    # variableMap: dict = field(default_factory=lambda:{})\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        with open(self.defFile,'r',encoding='utf-8-sig') as f:\n",
    "            self.DEF = f.readlines()\n",
    "            \n",
    "        arrID = '-1'\n",
    "        for i,l in enumerate(self.DEF):\n",
    "            if i == 0:\n",
    "                self.defTimestamp  = l.rstrip()\n",
    "            elif i == 1:\n",
    "                self.defTimestamp = self.defTimestamp + ' ' + l.rstrip()\n",
    "                self.defTimestamp = pd.to_datetime(self.defTimestamp,format='%m/%d/%Y %H:%M:%S').strftime(format=self.__dataclass_fields__['fileTimestamp'].default)\n",
    "            k = 'Program:'\n",
    "            if k in l:\n",
    "                self.programName = l.split(k)[-1].rstrip('-\\n').lstrip()\n",
    "            k = 'Wiring for'\n",
    "            if k in l:\n",
    "                self.LoggerModel = l.split(k)[-1].rstrip('-\\n').lstrip()\n",
    "            if 'Output_Table' in l:\n",
    "                l = l.rstrip('-\\n').replace('  ',' ').split(' ')\n",
    "                arrID = l[0]\n",
    "                frequency = pd.to_timedelta(self.parseFreq(f\"{l[2]} {l[3]}\")).total_seconds()\n",
    "                self.Arrays[arrID] = {}\n",
    "                self.Arrays[arrID]['variableMap'] = {}\n",
    "                self.Arrays[arrID]['DataFrame'] = []\n",
    "                self.Arrays[arrID]['Frequency'] = str(frequency)+'s'\n",
    "            elif arrID != '-1' and l == '\\n':\n",
    "                arrID = '-1'\n",
    "            elif arrID != '-1' :\n",
    "                l = l.rstrip('\\n').split(' ')\n",
    "                operation = 'Smp'\n",
    "                if l[0] == '1':\n",
    "                    name = 'ArrayID'\n",
    "                    dataType = 'int32'\n",
    "                else:\n",
    "                    name = l[1]\n",
    "                    if len(name.split('_'))>1:\n",
    "                        operation = name.split('_')[-1]\n",
    "                    if operation == 'RTM':\n",
    "                        dataType = 'int32'\n",
    "                    else:\n",
    "                        dataType = 'float32'\n",
    "                self.Arrays[arrID]['variableMap'][name] = {}\n",
    "                self.Arrays[arrID]['variableMap'][name]['operation'] = operation\n",
    "                self.Arrays[arrID]['variableMap'][name]['dataType'] = dataType\n",
    "                self.Arrays[arrID]['variableMap'][name]['ignore'] = dataType == 'float32'\n",
    "                \n",
    "@dataclass(kw_only=True)\n",
    "class parseMixedArray(parseDEF):\n",
    "    sourceFile: str\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        with open(self.sourceFile) as file:\n",
    "            MA = [l.rstrip('\\n').split(',') for l in file.readlines()]\n",
    "        super().__post_init__()\n",
    "        for i,row in enumerate(MA):\n",
    "            if len(row) == len(self.Arrays[row[0]]['variableMap']):\n",
    "                self.Arrays[row[0]]['DataFrame'].append(row[1:])\n",
    "            else:\n",
    "                if self.verbose:print(f'row {i} length does not match {self.defFile}')\n",
    "        for arrID in self.Arrays:\n",
    "            self.Arrays[arrID]['DataFrame'] = pd.DataFrame(self.Arrays[arrID]['DataFrame'],\n",
    "                                                           columns=list(self.Arrays[arrID]['variableMap'].keys())[1:])\n",
    "            na_value=['6999','-6999']\n",
    "            for val in na_value:\n",
    "                self.Arrays[arrID]['DataFrame'] = self.Arrays[arrID]['DataFrame'].replace(val,np.nan)\n",
    "            dtCols = ['Year_RTM', 'Day_RTM', 'Hour_Minute_RTM']\n",
    "            if not sum([c in self.Arrays[arrID]['DataFrame'] for c in dtCols]) == len(dtCols):\n",
    "                sys.exit('Timestamp format currently not supported.  Should ba a simple fix')\n",
    "            Date = self.Arrays[arrID]['DataFrame'][['Year_RTM', 'Day_RTM']].astype(int).astype(str).agg(' '.join,axis=1)\n",
    "            Date = pd.to_datetime(Date,format = '%Y %j')\n",
    "\n",
    "            Time = self.Arrays[arrID]['DataFrame']['Hour_Minute_RTM'].astype(int).astype(str)\n",
    "            Time = [t.zfill(4) for t in Time]\n",
    "            Time = [t[0:2]+':'+t[2:]+':'+'00' for t in Time]\n",
    "            Time = pd.to_timedelta(Time)\n",
    "            self.Arrays[arrID]['DataFrame'].index = Date+Time\n",
    "            self.Arrays[arrID]['DataFrame'] = self.Arrays[arrID]['DataFrame'].astype('float32')\n",
    "                \n",
    "MixedArray = r\"U:\\EC_Backup\\SCL_Data\\20250514\\WX_data.dat\"\n",
    "DEF_file = r\"C:\\Users\\jskeeter\\gsc-permafrost\\DataLoggerPrograms\\SwissCheeseLake_2024\\OverWinter.DEF\"\n",
    "d = parseMixedArray(sourceFile=MixedArray,defFile=DEF_file,verbose=True)\n",
    "# d.Arrays\n",
    "d.Arrays['101']['DataFrame'].columns\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df = d.Arrays['101']['DataFrame']#.resample('D').max()\n",
    "df = df.loc[((df.index.year==2025)&(df.index.month==4))]\n",
    "fig,ax=plt.subplots(2)\n",
    "ax[0].scatter(df['Current_AVG'],df['SlrW_AVG'])\n",
    "ax[1].plot(df['Voltage_AVG'])\n",
    "# df['Voltage_AVG'].plot(ax=ax[0])\n",
    "# df['Current_AVG'].plot(ax=ax[1])\n",
    "# fig.autofmt_xdate()\n",
    "# df[['Voltage_AVG','Current_AVG']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "import os\n",
    "import shutil\n",
    "import dbPipeline\n",
    "import time\n",
    "from parseFiles.helperFunctions.loadDict import loadDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "projectPath = os.path.join(os.getcwd(),'test')\n",
    "try:\n",
    "    shutil.rmtree(projectPath)\n",
    "except:\n",
    "    pass\n",
    "db = dbPipeline.database(projectPath=projectPath,verbose=False,enableParallel=True)\n",
    "Sites = r'example_data\\projectInventory_Template.yml'\n",
    "db.projectInventory(newSites=Sites)\n",
    "\n",
    "template = loadDict(r'example_data\\source_Template.yml')\n",
    "rootPath = r'example_chode'\n",
    "# for siteID in template:\n",
    "#     for measurementID in template[siteID]:\n",
    "#         print(siteID,measurementID)\n",
    "#         db.rawFileSearch(siteID,measurementID,template[siteID][measurementID])\n",
    "\n",
    "\n",
    "siteID,measurementID = 'SCL','Met'\n",
    "\n",
    "template[siteID][measurementID]['rootPath'] = r'C:\\Users\\jskeeter\\gsc-permafrost\\SCL_2024\\20240912'\n",
    "db.rawFileSearch(siteID,measurementID,template[siteID][measurementID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "df = dbPipeline.databaseFolder(path=r'C:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\database\\SCL\\Met',Years=[2024])\n",
    "df.dataOut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dataOut.to_csv(r'C:\\Users\\jskeeter\\OneDrive - NRCan RNCan\\Documents\\Presentations\\CANCH4\\Data\\SCL_met.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class test:\n",
    "    a: str = 'a'\n",
    "\n",
    "    def __post_init__(self,b=None):\n",
    "        print(b)\n",
    "\n",
    "test().__post_init__('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass,field,asdict\n",
    "\n",
    "@dataclass\n",
    "class a:\n",
    "    a:str=field(default='a',repr=True)\n",
    "    z:str=field(default='z',repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.b = 'b'\n",
    "    \n",
    "    def blorb(self):\n",
    "        self.chou = 'pi'\n",
    "\n",
    "c = a()\n",
    "c.blorb()\n",
    "def filt(dc):\n",
    "    print(dc)\n",
    "    return({'a':'a'})\n",
    "asdict(c,dict_factory=dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parseFiles.helperFunctions.loadDict import loadDict\n",
    "# importlib.reload(dbPipeline)\n",
    "\n",
    "# db = dbPipeline.database(projectPath=projectPath,verbose=False,enableParallel=False)\n",
    "template = loadDict(r'example_data\\source_Template.yml')\n",
    "# # sourcePath = r'U:\\EC_Backup\\SCL_2024\\20240724'\n",
    "sourcePath = r'example_data'\n",
    "for siteID in template:\n",
    "    for measurementID in template[siteID]:\n",
    "        db.rawFileSearch(siteID,measurementID,sourcePath=sourcePath,**template[siteID][measurementID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "importlib.reload(dbPipeline)\n",
    "path = projectPath + r'\\database\\SCL\\Met'\n",
    "path = projectPath + r'\\database\\SCL\\WSM_Profile'\n",
    "f = dbPipeline.databaseFolder(path = path,Years= 2024)\n",
    "fig = plt.figure()\n",
    "Data = f.dataOut\n",
    "# Data.loc[((Data['AirTC_Avg']>50)|(Data['AirTC_Avg']<-60)),'AirTC_Avg']=np.nan\n",
    "# plt.plot(Data['AirTC_Avg'])\n",
    "plt.plot(Data['TS_1_2_1'])\n",
    "plt.plot(Data['TS_2_2_1'])\n",
    "plt.plot(Data['TS_3_2_1'])\n",
    "plt.plot(Data['TS_4_2_1'])\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rawDataFile\n",
    "import importlib\n",
    "importlib.reload(rawDataFile)\n",
    "rd = rawDataFile.TOB3(sourceFile=r'u:\\EC_Backup\\SCL_2024\\20240912\\Flux_Data495.dat')\n",
    "# rd.Data['Diagnostic_CSAT']=0\n",
    "rd.Data.to_csv('SCL_Data_'+rd.fileTimestamp+'.dat',index=False)\n",
    "# 'Flux_Data_'+rd.fileTimestamp+'.dat'\n",
    "# rd.fileTimestamp\n",
    "# rd.Data.to_csv('Test.dat')\n",
    "# plt.figure()\n",
    "# plt.plot(rd.Data['Diagnostic_CSAT'][:-1])\n",
    "rd.Data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "ini = configparser.ConfigParser()\n",
    "ini.read(r'config_files/GHG_md_template.metadata')\n",
    "for s in ini.sections():\n",
    "    if s != 'Files':\n",
    "        for key,value in (ini[s].items()):\n",
    "            ini[s][key] = ''\n",
    "ini\n",
    "\n",
    "with open(r'config_files/GHG_ep_template.metadata', 'w') as f:\n",
    "    f.write(';GHG_METADATA\\n')\n",
    "    ini.write(f,space_around_delimiters=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
