{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database.py\n",
    "\n",
    "* Create an empty database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing empty database\n",
      "Creating folder:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\_metadata.yml\n",
      "Creating file:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\_logfile.txt\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "# see: database.py\n",
    "import database as pyDB\n",
    "importlib.reload(pyDB)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define a \"test folder\" for database\n",
    "dbpth = os.path.join(os.getcwd(),'test')\n",
    "# Delete previous \"test folder\" if it already exists\n",
    "if os.path.isdir(dbpth): shutil.rmtree(dbpth)\n",
    "\n",
    "# print('Fix initalization redundancy')\n",
    "\n",
    "#Create an empty database\n",
    "db = pyDB.database(projectPath=dbpth,\n",
    "    # siteID=['SCL'],\n",
    "    # Years=[str(y) for y in range(2024,2026)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data\n",
    "\n",
    "Create and add some arbitrary data\n",
    "<!-- 2) Add some arbitrary data\n",
    "3) Add new arbitrary data\n",
    "    * Example is done without overwriting existing values, option exists to overwrite values if needed -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing and documenting traces\n",
      "Re-named:  T*  to:  T_\n",
      "raw file Metadata: \n",
      "\n",
      " siteID: Test\n",
      "fileType: null\n",
      "loggerName: loggerName\n",
      "subSiteID: MetStation\n",
      "siteDescription: null\n",
      "replicateID: 1\n",
      "frequency: 30min\n",
      "timeZone: UTC\n",
      "lat: 0.0\n",
      "lon: 0.0\n",
      "Variables:\n",
      "  TA:\n",
      "    ignore: false\n",
      "    name_in: TA\n",
      "    unit_in: null\n",
      "    safe_name: TA\n",
      "    dtype: <i8\n",
      "    variableDescription: null\n",
      "  T_:\n",
      "    ignore: false\n",
      "    name_in: T*\n",
      "    unit_in: null\n",
      "    safe_name: T_\n",
      "    dtype: <f8\n",
      "    variableDescription: null\n",
      "  Garb:\n",
      "    ignore: true\n",
      "    name_in: Garb\n",
      "    unit_in: null\n",
      "    safe_name: Garb\n",
      "    dtype: '|O'\n",
      "    variableDescription: null\n",
      " \n",
      "\n",
      "Dropping non-numeric data\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2024\\Test\\raw\\MetStation\\POSIX_timestamp\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2024\\Test\\raw\\MetStation\\TA\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2024\\Test\\raw\\MetStation\\T_\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2025\\Test\\raw\\MetStation\\POSIX_timestamp\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2025\\Test\\raw\\MetStation\\TA\n",
      "Writing:  c:\\Users\\jskeeter\\gsc-permafrost\\EC_dataPipeline\\test\\2025\\Test\\raw\\MetStation\\T_\n"
     ]
    }
   ],
   "source": [
    "# Accepts pandas dataframe and dict of metadata as key inputs\n",
    "# Normally would be parsed from a file using other scripts (see rawDataFile.py)\n",
    "# Just a dummy example here for illustration purposes\n",
    "\n",
    "import rawDataFile\n",
    "importlib.reload(rawDataFile)\n",
    "importlib.reload(pyDB)\n",
    "\n",
    "db = pyDB.database(projectPath=dbpth,\n",
    "    )\n",
    "\n",
    "# A dummy dataset with two traces\n",
    "testData = pd.DataFrame(\n",
    "    index=pd.DatetimeIndex(['2024-12-31 23:30', '2025-01-01 00:00', '2025-01-01 00:30','2025-01-01 01:00']),\n",
    "    data={'TA':[-1,-2,-3,-4],\n",
    "          'T*':[-1.0,-2.00002,-3.0,-4.2],\n",
    "          'Garb':['some','text','to','ignore']}\n",
    ")\n",
    "\n",
    "# genericLoggerFile() takes data and metadata for a given file and formats them in a standardized way\n",
    "# typically called from a raw file parser function (e.g., hoboCSV)\n",
    "testData = rawDataFile.genericLoggerFile(siteID='Test',subSiteID='MetStation',Data=testData)\n",
    "\n",
    "# Call the import\n",
    "db.rawDatabaseImport(testData.Data,testData.Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pyDB.database(projectPath=dbpth,verbose=False\n",
    "    )\n",
    "\n",
    "# A dummy dataset with two traces to update\n",
    "# It spans the time period of the original (but with an erroneous null value) and then includes one updated value\n",
    "testUpdate = pd.DataFrame(\n",
    "    index=pd.DatetimeIndex(['2024-12-31 23:30', '2025-01-01 00:00', '2025-01-01 00:30','2025-01-01 01:00','2025-01-01 01:30']),\n",
    "    data={'TA':[-1,-2,-3,-9999,-5],\n",
    "          'T*':[-1.0,-2.00002,-3.0,np.nan,-5.1],}\n",
    ")\n",
    "\n",
    "# Format the data\n",
    "testUpdate = rawDataFile.genericLoggerFile(siteID='Test',subSiteID='MetStation',Data=testUpdate,verbose=db.verbose)\n",
    "\n",
    "\n",
    "# Call the import\n",
    "# Will by default, only fill nan-values in the original database trace\n",
    "# The null values from the incoming array won't have any impact on the existing data \n",
    "# but the timestamps which don't exist in the database will be written\n",
    "\n",
    "db.rawDatabaseImport(testData.Data,testData.Metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
